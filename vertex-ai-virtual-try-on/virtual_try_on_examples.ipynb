{
  "cells": [
    {
      "cell_type": "code",
      "id": "vKm6Z4hKnU95Cymg7lNgyxrd",
      "metadata": {
        "tags": [],
        "id": "vKm6Z4hKnU95Cymg7lNgyxrd"
      },
      "source": [
        "# Copyright 2025 Google LLC\n",
        "# Copyright Richard He Modified on 2025\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Original notebook source from https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/vision/getting-started/virtual_try_on.ipynb"
      ],
      "metadata": {
        "id": "vlsuNOlAKIEf"
      },
      "id": "vlsuNOlAKIEf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ],
      "metadata": {
        "id": "vABcNNmowtaN"
      },
      "id": "vABcNNmowtaN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import typing\n",
        "import urllib.request\n",
        "\n",
        "import IPython.display\n",
        "from PIL import Image as PIL_Image\n",
        "from PIL import ImageOps as PIL_ImageOps\n",
        "from google import genai\n",
        "from google.genai.types import (\n",
        "    GenerateImagesConfig,\n",
        "    Image,\n",
        "    ProductImage,\n",
        "    RecontextImageConfig,\n",
        "    RecontextImageSource,\n",
        ")\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "B2kuufPfxAc9"
      },
      "id": "B2kuufPfxAc9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PROJECT_ID = \"rocketech-de-pgcp-sandbox\"  # @param {type: \"string\", placeholder: \"[your-project-id]\", isTemplate: true}\n",
        "LOCATION = 'europe-west4' # @param {type: \"string\", placeholder: \"[location]\", isTemplate: true}\n",
        "virtual_try_on_model = \"virtual-try-on-preview-08-04\"\n",
        "image_generation = \"imagen-4.0-generate-001\"\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "IM64z4ASxD-B"
      },
      "id": "IM64z4ASxD-B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display media in the notebook\n",
        "\n",
        "def display_image(\n",
        "    image,\n",
        "    max_width: int = 400,\n",
        "    max_height: int = 400,\n",
        ") -> None:\n",
        "    pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
        "    if pil_image.mode != \"RGB\":\n",
        "        # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
        "        pil_image = pil_image.convert(\"RGB\")\n",
        "    image_width, image_height = pil_image.size\n",
        "    if max_width < image_width or max_height < image_height:\n",
        "        # Resize to display a smaller notebook image\n",
        "        pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
        "    IPython.display.display(pil_image)\n",
        "\n",
        "\n",
        "def display_local_image(\n",
        "    images: list[str],\n",
        ") -> None:\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(12, 6))\n",
        "    if len(images) == 1:\n",
        "        axes = np.array([axes])\n",
        "    for i, ax in enumerate(axes):\n",
        "        image = img.imread(images[i])\n",
        "        ax.imshow(image)\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "WiHu4z76xSJa"
      },
      "id": "WiHu4z76xSJa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to recontext the image (virtrual try on in action)\n",
        "\n",
        "def virtual_try_on(person_image: Image, product_images: Image) -> Image:\n",
        "  response = client.models.recontext_image(\n",
        "    model=virtual_try_on_model,\n",
        "    source=RecontextImageSource(\n",
        "        person_image=person_image,\n",
        "        product_images=[\n",
        "            ProductImage(product_image=product_images)\n",
        "        ],\n",
        "    ),\n",
        "    config=RecontextImageConfig(\n",
        "        base_steps=32,\n",
        "        number_of_images=1,\n",
        "        safety_filter_level=\"BLOCK_LOW_AND_ABOVE\",\n",
        "        person_generation=\"ALLOW_ADULT\",\n",
        "    ),\n",
        "  )\n",
        "\n",
        "  return response.generated_images[0].image"
      ],
      "metadata": {
        "id": "-LYD2R0UxdEW"
      },
      "id": "-LYD2R0UxdEW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate image using the Imagen model, only generate one at a time for now to keep it simple\n",
        "\n",
        "def generate_image(prompt: str, no_human=True) -> Image:\n",
        "\n",
        "  image = client.models.generate_images(\n",
        "    model=image_generation,\n",
        "    prompt=prompt,\n",
        "    config=GenerateImagesConfig(\n",
        "        number_of_images=1,\n",
        "        image_size=\"1K\", # 2k is the max resolution supported now\n",
        "        safety_filter_level=\"BLOCK_LOW_AND_ABOVE\", # safest setting, see more safety level here https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters#how-to-configure\n",
        "        person_generation=\"ALLOW_ADULT\",\n",
        "    ),\n",
        "  )\n",
        "\n",
        "  return image.generated_images[0].image"
      ],
      "metadata": {
        "id": "YlDeaLfxyuB-"
      },
      "id": "YlDeaLfxyuB-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Human model samples with matching clothing to use virtual try on prompts\n",
        "\n",
        "sample_sets = [\n",
        "  {\n",
        "    \"id\": 1,\n",
        "    \"human_model_prompt\": \"A full-body, front-view photograph of a woman standing in a professional photo studio with a plain white background.\",\n",
        "    \"clothing_to_try\": [\n",
        "      \"A flat-lay of a white t-shirt with a tree shaped logo at the front\",\n",
        "      \"A neatly folded pair of plain dark-wash skinny jeans.\",\n",
        "      \"A top-down shot of a pair of simple red ballet flats, with no visible branding.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"id\": 2,\n",
        "    \"human_model_prompt\": \"A full-body, side-view photograph of a man standing in a studio with a neutral gray seamless paper background.\",\n",
        "    \"clothing_to_try\": [\n",
        "      \"A crisp white oxford button-down shirt, carefully folded, with a small, discreet text logo 'Origin' embroidered on the cuff.\",\n",
        "      \"A pair of plain, tailored gray wool trousers, laid flat.\",\n",
        "      \"A profile shot of a single polished black leather oxford shoe against a white background.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"id\": 3,\n",
        "    \"human_model_prompt\": \"A three-quarter view, full-body photograph of a woman posing in a photography studio against a soft beige backdrop.\",\n",
        "    \"clothing_to_try\": [\n",
        "      \"A plain forest green cashmere V-neck sweater, laid flat on a white surface.\",\n",
        "      \"A black A-line knee-length corduroy skirt, displayed on a ghost mannequin, featuring a small embroidered logo of a fox near the hem.\",\n",
        "      \"A pair of plain black leather knee-high boots with a flat sole, standing upright against a plain background.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"id\": 4,\n",
        "    \"human_model_prompt\": \"A full-body, back-view photograph of a man in a studio setting with a light gray background.\",\n",
        "    \"clothing_to_try\": [\n",
        "      \"A studio product shot of a plain charcoal gray bomber jacket with a silver zipper.\",\n",
        "      \"A flat-lay of a pair of straight-leg black denim jeans.\",\n",
        "      \"A three-quarter view of a pair of clean white leather court sneakers with a simple text-based logo 'Apex' embossed on the side.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"id\": 5,\n",
        "    \"human_model_prompt\": \"A low-angle, full-body photograph of a woman posing in a studio with a clean white cyclorama wall.\",\n",
        "    \"clothing_to_try\": [\n",
        "      \"A flat-pack image of a vibrant yellow sleeveless blouse with a tie-neck, showcasing an intricate, multi-colored image-based logo of a peacock feather on the collar.\",\n",
        "      \"A pair of plain white wide-leg capri pants, neatly folded.\",\n",
        "      \"A pair of plain tan espadrille wedge sandals, shot from a slightly elevated angle.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"id\": 6,\n",
        "    \"human_model_prompt\": \"A high-angle, three-quarter view, full-body photograph of a man in a photo studio with a dark charcoal background.\",\n",
        "    \"clothing_to_try\": [\n",
        "      \"An olive green utility shirt with two button-flap chest pockets, laid flat and showing no logos.\",\n",
        "      \"A pair of beige cargo shorts with a text-based logo 'Nomad' printed subtly above the back pocket.\",\n",
        "      \"A close-up, detailed shot of a pair of brown suede hiking boots with an image-based logo of a mountain peak stamped onto the heel.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"id\": 7,\n",
        "    \"human_model_prompt\": \"A high-resolution, full-body, head-on photograph of a woman standing in a brightly lit professional photography studio wearing a dress. The backdrop is clean gray paper.\",\n",
        "    \"clothing_to_try\": [\n",
        "      \"A studio photograph of a floor-length black silk evening gown with a thigh-high slit, displayed on a ghost mannequin.\",\n",
        "      \"A product shot of a deep burgundy velvet mermaid gown with an off-the-shoulder neckline and a dramatic flared hem, presented on a ghost mannequin to highlight its silhouette.\",\n",
        "      \"A pair of strappy, high-heeled sandals in a metallic silver finish, featuring a small, intricate image-based logo of a crescent moon on the sole.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"id\": 8,\n",
        "    \"human_model_prompt\": \"A static, full-body (including shoes), direct front-on photograph of 3 women in a studio with even lighting against a white background.\",\n",
        "    \"clothing_to_try\": [\n",
        "      \"A professional single-button black blazer on a mannequin, with a small, text-based logo 'Elysian' on the inner lining.\",\n",
        "      \"A pair of plain, matching black tailored trousers, hung on a rack.\",\n",
        "      \"A pair of nude-colored pointed-toe pumps, shot from a low angle.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"id\": 9,\n",
        "    \"human_model_prompt\": \"A full-body, side-view photograph of a man leaning against a prop block in a studio with a textured gray background.\",\n",
        "    \"clothing_to_try\": [\n",
        "      \"A flat-lay of a burgundy crewneck sweatshirt featuring a complex, yellow text-based logo in a serif font that reads 'Northbound Collective'.\",\n",
        "      \"A pair of light-wash relaxed-fit jeans with a torn knee, laid flat.\",\n",
        "      \"A pair of classic brown suede desert boots with no visible logos.\"\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"id\": 10,\n",
        "    \"human_model_prompt\": \"A dynamic, full-body (including shoes) photograph from a back three-quarter angle of a non-binary person, shot in a studio with a sky-blue background.\",\n",
        "    \"clothing_to_try\": [\n",
        "      \"A plain multi-colored windbreaker jacket in purple, teal, and yellow.\",\n",
        "      \"A pair of black nylon track pants featuring a recurring image-based logo of a simplified lightning bolt down the side stripe.\",\n",
        "      \"A pair of black high-top sneakers with reflective details, shot under dramatic studio lighting.\"\n",
        "    ]\n",
        "  }\n",
        "]"
      ],
      "metadata": {
        "id": "sMKLkR7o1v8Y"
      },
      "id": "sMKLkR7o1v8Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Virtual try on with one item applied at a time, total 3. Applying multiple items at the same time is currently not supported.\n",
        "\n",
        "def try_it(prompt_index):\n",
        "  human_model = generate_image(sample_sets[prompt_index]['human_model_prompt'], no_human=False)\n",
        "  display_image(human_model)\n",
        "\n",
        "  for i in sample_sets[prompt_index]['clothing_to_try']:\n",
        "    item = generate_image(i)\n",
        "    print(\"Displaying generated item...\")\n",
        "    display_image(item)\n",
        "    human_model = virtual_try_on(human_model, item) # replacing human_model so all of the items can be tried.\n",
        "    print(\"Displaying virtrual try on result...\")\n",
        "    display_image(human_model)"
      ],
      "metadata": {
        "id": "qia1w44QFMIh"
      },
      "id": "qia1w44QFMIh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try_it(0)"
      ],
      "metadata": {
        "id": "l12xqKlT16D2"
      },
      "id": "l12xqKlT16D2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try_it(2)"
      ],
      "metadata": {
        "id": "iNZGHseC-bP2"
      },
      "id": "iNZGHseC-bP2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try_it(8)"
      ],
      "metadata": {
        "id": "nRa-9-N9-bNr"
      },
      "id": "nRa-9-N9-bNr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try_it(9)"
      ],
      "metadata": {
        "id": "YwZfSOUk-a4Z"
      },
      "id": "YwZfSOUk-a4Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try_it(7)"
      ],
      "metadata": {
        "id": "IWofaTIJDuMn"
      },
      "id": "IWofaTIJDuMn",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "virtrual_try_on_examples"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
